##### [ARGB_888](http://en.wikipedia.org/wiki/RGBA_color_space#ARGB)
###### GlitchCog rework
Bit shifting. More detail on how the bits are shifted. Also more variation in the placement and sizes of the glitch blocks. Does Google+ still want to tag the face? In earlier versions it does and in later versions it doesn't. 
![combineGlitch](../project_images/combineGlitch.png?raw=true "combineGlitch")

###### DotCog rework
Dial the hue up, Dial the hue down. Match the most common colours

###### Recognise-detect
Looking at some of the test images I see that putting intervention zones around the eyes easily fools the face detection as expected but human viewers can still get a sense of the portrait. A long history of brain mutation allows us to see faces everywhere. The glitch zones are placed by algorithm but to help humans recognise the people in the photo, I avoid the eyes if I can see them. After the first few glitch and dot passes, if I still can still recognise a face a vertical shift breaks up the eye/nose/mouth lines.



